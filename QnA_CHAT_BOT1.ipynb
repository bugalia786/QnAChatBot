{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QnA_CHAT_BOT1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugalia786/QnAChatBot/blob/main/QnA_CHAT_BOT1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qC8ZsDMPq45i"
      },
      "source": [
        "# QnA_CHAT_BOT "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SG_yzXQRq_cq"
      },
      "source": [
        "## About The Dataset\n",
        "# The code is done based on the Babi Data Set from Facebook Research \n",
        "# Full Details: https://research.fb.com/downloads/babi/\n",
        "# - Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
        "#   \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
        "#   http://arxiv.org/abs/1502.05698"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPM5nPNOH7YK",
        "outputId": "0ce37250-c1f9-4f45-922a-ee9130c2c878"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_O3o8MArDlZ"
      },
      "source": [
        "#importing libraries\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "#loading training and test data\n",
        "with open(\"/content/drive/MyDrive/train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    train_data =  pickle.load(fp)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
        "    test_data =  pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvdSrl18g9x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av3b8_9_rgi8",
        "outputId": "ba48fbbc-b8ce-4896-d173-74e9cada1d70"
      },
      "source": [
        "#The dataset consists of three parts \n",
        "#1. The part to train on(input text)\n",
        "#2. The binary question asked\n",
        "#3. Binary answer to the question\n",
        "#some of the examples are written below\n",
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['Mary',\n",
              "  'moved',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bathroom',\n",
              "  '.',\n",
              "  'Sandra',\n",
              "  'journeyed',\n",
              "  'to',\n",
              "  'the',\n",
              "  'bedroom',\n",
              "  '.'],\n",
              " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
              " 'no')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxcraQNArqfj"
      },
      "source": [
        "# Create a set that holds the vocab words\n",
        "vocab = set()\n",
        "all_data = test_data + train_data\n",
        "for story, question , answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "vocab.add('no')\n",
        "vocab.add('yes')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHLGGESorxsG",
        "outputId": "8503a2e0-6b5a-46c2-923d-1990dcdc871e"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHW__-Dpryqc"
      },
      "source": [
        "vocab_len = len(vocab) + 1 \n",
        "#we add an extra space to hold a 0 for Keras's pad_sequences\n",
        "max_story_len = max([len(data[0]) for data in all_data])\n",
        "max_question_len = max([len(data[1]) for data in all_data])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyYKVE4rzrP"
      },
      "source": [
        "vocab_size = len(vocab) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1dUsjNor1T3"
      },
      "source": [
        "#importing libraries for padding and tokenization of data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cMCb2fhr2O6"
      },
      "source": [
        "# integer encode sequences of words\n",
        "tokenizer = Tokenizer(filters=[])\n",
        "tokenizer.fit_on_texts(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krN-u4L4r3tG"
      },
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story,question,answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPdQvp3jr6yc"
      },
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2HCbluusGOj",
        "outputId": "b0540b8a-4eb5-4b86-c8e1-dfade1e51c26"
      },
      "source": [
        "len(train_story_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcB6WFs5sHfJ"
      },
      "source": [
        "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
        "    '''\n",
        "    INPUT: \n",
        "    \n",
        "    data: consisting of Stories,Queries,and Answers\n",
        "    word_index: word index dictionary from tokenizer\n",
        "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
        "    max_question_len: length of the longest question (used for pad_sequences function)\n",
        "    OUTPUT:\n",
        "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
        "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
        "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
        "    \n",
        "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
        "    '''\n",
        "    \n",
        "    \n",
        "    # X = STORIES\n",
        "    X = []\n",
        "    # Xq = QUERY/QUESTION\n",
        "    Xq = []\n",
        "    # Y = CORRECT ANSWER\n",
        "    Y = []\n",
        "    \n",
        "    \n",
        "    for story, query, answer in data:\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        y = np.zeros(len(word_index) + 1)\n",
        "        y[word_index[answer]] = 1\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWctvhOssaxQ"
      },
      "source": [
        "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZR25AOaRsc6U"
      },
      "source": [
        "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnpy9DafseHl"
      },
      "source": [
        "#CREATING THE MODEL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT_-HzpVsk8C"
      },
      "source": [
        "#Importing the lib to create the model \n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
        "from keras.layers import add, dot, concatenate\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUMQqZ97srtw"
      },
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB-VsqOBsuBH"
      },
      "source": [
        "# Input gets embedded to a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "\n",
        "# This encoder will output:\n",
        "# (samples, story_maxlen, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZJ42FnQsz8_"
      },
      "source": [
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW4Vt4eks2mj"
      },
      "source": [
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=max_question_len))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyBafBhhs4Vi"
      },
      "source": [
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fohrCctds6sV"
      },
      "source": [
        "# shape: `(samples, story_maxlen, query_maxlen)`\n",
        "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
        "match = Activation('softmax')(match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uYV-SxLtAJZ"
      },
      "source": [
        "response = add([match, input_encoded_c]) \n",
        "response = Permute((2, 1))(response)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-DAEE7_tD3t"
      },
      "source": [
        "answer = concatenate([response, question_encoded])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLAKLKW5tFnm"
      },
      "source": [
        "answer = LSTM(32)(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s9RznOHtIAz"
      },
      "source": [
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_size)(answer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6OG-l9RtJzQ"
      },
      "source": [
        "answer = Activation('softmax')(answer)\n",
        "model = Model([input_sequence, question], answer)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQUPh7PtOCY",
        "outputId": "39ae0811-397b-44c8-9889-0b0114c49927"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 156)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential (Sequential)         (None, None, 64)     2432        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_2 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 156, 6)       0           sequential[0][0]                 \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 156, 6)       0           dot[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "sequential_1 (Sequential)       (None, None, 6)      228         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 156, 6)       0           activation[0][0]                 \n",
            "                                                                 sequential_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "permute (Permute)               (None, 6, 156)       0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 6, 220)       0           permute[0][0]                    \n",
            "                                                                 sequential_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     (None, 32)           32384       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32)           0           lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 38)           1254        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 38)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 38,730\n",
            "Trainable params: 38,730\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgbuvuUxtPfS"
      },
      "source": [
        "#history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2Sut5fFtTeR"
      },
      "source": [
        "filename = 'chatbot_120_epochs.h5'\n",
        "#model.save(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viwoYt3TvoKE"
      },
      "source": [
        "# #Visualizing the results\n",
        "# import matplotlib.pyplot as plt\n",
        "# # %matplotlib inline\n",
        "# print(history.history.keys())\n",
        "# # summarize history for accuracy\n",
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'test'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YND-QAsyx3-9"
      },
      "source": [
        "# Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06kWNogvxfP3"
      },
      "source": [
        "model.load_weights(filename)\n",
        "pred_results = model.predict(([inputs_test, queries_test]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9D5GWZgx6Je",
        "outputId": "a893633b-5d44-4006-e085-cf7cbf86e161"
      },
      "source": [
        "story =' '.join(word for word in test_data[0][0])\n",
        "print(story)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mary got the milk there . John moved to the bedroom .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHoZcgfEx8Pu",
        "outputId": "aa5d6c9d-d7fe-47bb-d8b9-66349b3a9ec1"
      },
      "source": [
        "query = ' '.join(word for word in test_data[0][1])\n",
        "print(query)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is John in the kitchen ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92zzwcOCx9cW",
        "outputId": "a1690090-51ca-4710-aa20-c4dcae54b150"
      },
      "source": [
        "print(\"True Test Answer from Data is:\",test_data[0][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Test Answer from Data is: no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of_ueypOx_9s",
        "outputId": "262feaee-ae90-48a5-b0b9-896ba19fafb0"
      },
      "source": [
        "#Generate prediction from model\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  john\n",
            "Probability of certainty was:  0.999992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ox_MZw2yBU9"
      },
      "source": [
        "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
        "# my_story.split()\n",
        "my_question = \"Is the football in the garden ?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dA5HHq4yH4G",
        "outputId": "d9e67425-3349-45f5-8b3c-20df4547a98c"
      },
      "source": [
        "mydata = [(my_story.split(),my_question.split(),'yes')]\n",
        "my_story,my_ques,my_ans = vectorize_stories(mydata)\n",
        "pred_results = model.predict(([ my_story, my_ques]))\n",
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, val in tokenizer.word_index.items():\n",
        "    if val == val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is: \", k)\n",
        "print(\"Probability of certainty was: \", pred_results[0][val_max])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted answer is:  took\n",
            "Probability of certainty was:  0.68173075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyAzOgVlEfkH"
      },
      "source": [
        "# !pip install fastapi nest-asyncio pyngrok uvicorn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3EXMVmFEgDs"
      },
      "source": [
        "# from fastapi import FastAPI\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "# app = FastAPI()\n",
        "\n",
        "# app.add_middleware(\n",
        "#     CORSMiddleware,\n",
        "#     allow_origins=['*'],\n",
        "#     allow_credentials=True,\n",
        "#     allow_methods=['*'],\n",
        "#     allow_headers=['*'],\n",
        "# )\n",
        "\n",
        "# @app.get('/')\n",
        "# async def root():\n",
        "#     return {'hello': 'world'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iU1VdN7JXzV",
        "outputId": "1db862c4-4a9f-442d-a777-abe988f2c807"
      },
      "source": [
        "!pip install fastapi\n",
        "from unicodedata import category\n",
        "from fastapi import FastAPI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (0.68.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (1.8.2)\n",
            "Requirement already satisfied: starlette==0.14.2 in /usr/local/lib/python3.7/dist-packages (from fastapi) (0.14.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isWR3wAkJlgy"
      },
      "source": [
        "app = FastAPI()\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {\"Hello\": \"World\"}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laIF3U5dEgG6"
      },
      "source": [
        "@app.post('/answer')\n",
        "def answer(story : str,question: str):\n",
        "    mydata = [(story.split(),question.split(),'yes')]\n",
        "    story,ques,ans = vectorize_stories(mydata)\n",
        "    pred_results = model.predict(([ story, ques]))\n",
        "    val_max = np.argmax(pred_results[0])\n",
        "\n",
        "    for key, val in tokenizer.word_index.items():\n",
        "        if val == val_max:\n",
        "            k = key\n",
        "    a= float(pred_results[0][val_max])\n",
        "    return {'Predicted answer is: ': k,'Probability of certainty was:':a}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKPbKqfgNJB8",
        "outputId": "8ca5b50b-a98c-452b-a709-16d52c4a3534"
      },
      "source": [
        "pred_results[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2.6554528e-07, 2.7135815e-07, 3.0879411e-07, 2.8571756e-07,\n",
              "       2.9834882e-07, 3.0204853e-07, 3.1825903e-01, 2.5781628e-07,\n",
              "       2.6778449e-07, 2.7699431e-07, 3.3015203e-07, 2.2425674e-07,\n",
              "       3.0668340e-07, 2.9293841e-07, 2.1323149e-07, 2.5143507e-07,\n",
              "       2.5090688e-07, 3.2931962e-07, 3.1349813e-07, 6.8173075e-01,\n",
              "       3.0027988e-07, 2.9106013e-07, 3.0506911e-07, 2.5092794e-07,\n",
              "       2.4694745e-07, 3.3313833e-07, 3.4973414e-07, 2.2572350e-07,\n",
              "       2.2105615e-07, 2.4083639e-07, 2.6148251e-07, 3.0220181e-07,\n",
              "       3.0403311e-07, 2.9097353e-07, 2.4309293e-07, 3.4899477e-07,\n",
              "       3.2914377e-07, 2.5384125e-07], dtype=float32)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU-yf-pXJ3JM",
        "outputId": "5140711e-7043-4fa8-ca9c-cd22b82c07c9"
      },
      "source": [
        "!pip install colabcode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: colabcode in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: nest-asyncio==1.4.3 in /usr/local/lib/python3.7/dist-packages (from colabcode) (1.4.3)\n",
            "Requirement already satisfied: jupyterlab==3.0.7 in /usr/local/lib/python3.7/dist-packages (from colabcode) (3.0.7)\n",
            "Requirement already satisfied: uvicorn==0.13.1 in /usr/local/lib/python3.7/dist-packages (from colabcode) (0.13.1)\n",
            "Requirement already satisfied: pyngrok>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from colabcode) (5.0.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (5.5.0)\n",
            "Requirement already satisfied: tornado>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (6.1)\n",
            "Requirement already satisfied: nbclassic~=0.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (0.3.1)\n",
            "Requirement already satisfied: jupyter-server~=1.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (1.10.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (4.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (21.0)\n",
            "Requirement already satisfied: jupyterlab-server~=2.0 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.7.2)\n",
            "Requirement already satisfied: jinja2>=2.10 in /usr/local/lib/python3.7/dist-packages (from jupyterlab==3.0.7->colabcode) (2.11.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (0.12.0)\n",
            "Requirement already satisfied: click==7.* in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from uvicorn==0.13.1->colabcode) (3.7.4.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.10->jupyterlab==3.0.7->colabcode) (2.0.1)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (22.2.1)\n",
            "Requirement already satisfied: jupyter-client>=6.1.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (6.1.12)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.2.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.0.5)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.11.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (5.1.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.8.0)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (20.1.0)\n",
            "Requirement already satisfied: requests-unixsocket in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.2.0)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (3.3.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.7/dist-packages (from jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<4,>=3.1.0->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.10)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client>=6.1.1->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.8.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.3)\n",
            "Requirement already satisfied: json5 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.9.6)\n",
            "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.2.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.9.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (57.4.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (4.6.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (21.2.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (0.18.0)\n",
            "Requirement already satisfied: notebook<7 in /usr/local/lib/python3.7/dist-packages (from nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (5.3.1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from notebook<7->nbclassic~=0.2->jupyterlab==3.0.7->colabcode) (4.10.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok>=5.0.0->colabcode) (3.13)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.3->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (2.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->jupyterlab==3.0.7->colabcode) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->jupyterlab==3.0.7->colabcode) (0.2.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (4.0.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter-server~=1.2->jupyterlab==3.0.7->colabcode) (0.5.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->jupyterlab==3.0.7->colabcode) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jupyterlab-server~=2.0->jupyterlab==3.0.7->colabcode) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8doUF7NKB7H"
      },
      "source": [
        "from colabcode import ColabCode\n",
        "server = ColabCode(port=10000, code=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fZCJLuJKG93",
        "outputId": "5f851541-774d-4b2a-bd02-f78241152d8b"
      },
      "source": [
        "server.run_app(app=app)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: NgrokTunnel: \"https://a8f4-35-229-200-190.ngrok.io\" -> \"http://localhost:10000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-JEWDMBEgJz"
      },
      "source": [
        "# import nest_asyncio\n",
        "# from pyngrok import ngrok\n",
        "# import uvicorn\n",
        "\n",
        "# ngrok_tunnel = ngrok.connect(8000)\n",
        "# print('Public URL:', ngrok_tunnel.public_url)\n",
        "# nest_asyncio.apply()\n",
        "# uvicorn.run(app, port=8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59XRTjUEgMx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO-89RkyEgPh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSnA0lPWyPzV"
      },
      "source": [
        "# THE END!!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcLjjMOiMR-6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}